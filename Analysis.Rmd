---
title: "Titanic"
author: "John Russell"
date: "1/7/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

When examining the improbable tragedy of the sinking of the Titanic in 1912, it is a reasonable assumption to believe that there was a predictable pattern to who on board survived and who died. It is my belief that women and younger passengers had a greater chance of surviving due to those groups likely taking priority when filling the lifeboats. A thorough analysis will be conducted to test this hypothesis.

```{r, include = F}
library(tidyverse)
train_data <- read_csv('train.csv')
```

## Data and Feature Engineering
```{r}
glimpse(train_data)
```

A quick look at the data shows that there are 891 passengers as well as 12 different variables, including whether or not the passenger survived.


```{r}
train_data <- train_data %>%
  select(-c(Cabin, Ticket))
```

We quickly notice that the Cabin number of passengers in rarely present, so we will omit this variable from the analysis as it does not provide any useful information for the prediction.
 
To properly examine age, it will be grouped as infant (0-5), child (6-12), teenager (13-19), young adult (20-29), adult (30-49), and elderly (50+). Before we can group the passengers, we need to deal with the patients with no age recorded. 

```{r}
train_data %>%
  mutate(Ageless = is.na(Age)) %>%
  count(Ageless)
```

We see that there are 177 passengers that do not have a recorded age in the data set. That is too many to just remove from the data set. In order to deal with this, we will use the other variables to find the most liekly age group for the passengers with no age and use the average value of that group to estimate the age. Because we are using age groups, the actual value is less important. 

```{r}
train_data <- train_data %>%
  mutate(Famsize = SibSp + Parch)

find_age <- group_by(train_data, Pclass, Sex, Fare, Famsize) %>%
  summarise(Avg_age = mean(Age, na.rm = T))
```

Now that we have an average age for passengers based on ticket class, gender, and the size of the family, we can assign this average age to the passengers with no recorded age. 

```{r}
train_data <- train_data %>%
  inner_join(find_age)

train_data %>%
  count(is.na(Avg_age))

for (i in 1:length(train_data$Age)){
  if (is.na(train_data$Age[i])){
    train_data$Age[i] <- train_data$Avg_age[i]
  }
}

train_data %>%
  count(is.nan(Age))
```

Now we see that there are only 7 passengers that are missing their age, and they all are part of the same family. We will remove these observations from the data set. 

Now that we have the ages accounted for, we can finish the featue engineering by creating the variable `Age_Group` and creating factors for `embarked`.

```{r}
train_data <- train_data %>%
  select(-c(SibSp, Parch, Avg_age)) %>%
  filter(!is.nan(Age)) %>%
  mutate(Age_Group = cut(Age, breaks = c(0, 5, 12, 19, 29, 49, 80), labels = c("Infant", "Child", "Teen", "Young Adult", "Adult", "Elderly")))

train_data$Embarked <- factor(train_data$Embarked)
```

We will save this updated training data set as a new CSV file.

```{r}
write_csv(train_data, path = "tidy_titanic.csv")
```


## Visualization

Now that we have our variables transformed, we can start to examine the data. The first thing we will do is look at the correlation between the predictors. 

```{r}
cor(train_data[, -c(2, 4:5, 8, 10)])
```

Most of what we see is expected. For example, the `Fare` is moderately negatively correlated with the `Pclass`, or ticket class. This means that the better the class (i.e. 1^st^) will have more expensive tickets. We now look at some graphs.

A simple bar chart will show us the survival based on age group.

```{r}
ggplot(train_data) +
  geom_bar(aes(Age_Group, fill = Age_Group))
```

A percentage of survival based on age group will be more informative. 

```{r}
 by_age <- train_data %>%
  group_by(Age_Group) %>%
  summarise(prop_lived = sum(Survived == 1) / n()) 

ggplot(by_age) +
  geom_col(aes(Age_Group, prop_lived, fill = Age_Group))
```

Now that we have a proportion of who lived by age group, we can see that it is true that young passengers did indeed have a greater chance of surviving, likely due to priority on the life boats. Now for gender.

Like with age, a simple bar chart will tell us a lot about how one group survives compared to the other.

```{r}
by_sex <- train_data %>%
  group_by(Sex) %>%
  summarise(proportion_lived = sum(Survived == 1) / n())

ggplot(by_sex) +
  geom_col(aes(Sex, proportion_lived, fill = Sex))
```

Gender is clearly a significant factor that determined which passengers survived. With both of these predictors analyzed visually, we can start building the model.

## Model Selection

Since we are dealing with a classification problem, we will consider a few different modeling methods: logistic regression, linear discriminant analysis, and quadratic discriminant analysis. Because we are dealing with a response that has two classes, logistic regression seems like a good place to start. For comparison's sake, We will be implementing the logisitc regression algorithm by hand and using the `glm` function provided in R.

Let's start with the `glm` function:

```{r}
log_fit <- glm(Survived ~ Pclass + Sex + Fare + Embarked + Famsize + Age_Group, data = train_data, family = binomial)

summary(log_fit)
```

We see that most of the variables look like they are significant. The only exception is the `Embarked` variable. In order to build the most accurate model, `Embarked` will be removed.

```{r}
log_fit2 <- glm(Survived ~ Pclass + Sex + Fare + Famsize + Age_Group, data = train_data, family = binomial)

summary(log_fit2)
```




